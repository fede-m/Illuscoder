{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fede-m/Illuscoder/blob/main/IllusCoder_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWkoIc7zPkEg"
      },
      "outputs": [],
      "source": [
        "# Things to install\n",
        "\n",
        "# 1) Install ngrok to start Flask application\n",
        "\n",
        "\n",
        "# 2) Summarize text\n",
        "!pip install sentencepiece\n",
        "\n",
        "\n",
        "# 3) Named Entity Recognition and Corefernce\n",
        "!python -m pip install spacy==2.1.0\n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "\n",
        "# 4) Generate images\n",
        "!pip install diffusers==0.8.0 transformers ftfy\n",
        "!pip install accelerate\n",
        "\n",
        "# 5) Modify images\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyHEDlUXkRjq"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import json\n",
        "\n",
        "# Text summarizer\n",
        "from transformers import pipeline\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import random\n",
        "\n",
        "# Named Entity Recognition\n",
        "import spacy\n",
        "\n",
        "#Coreference\n",
        "!pip uninstall neuralcorefY\n",
        "\n",
        "!pip install neuralcoref --no-binary neuralcoref\n",
        "import neuralcoref\n",
        "\n",
        "# Stable Diffusion Models\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers import DPMSolverMultistepScheduler\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "#check for gpu\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "#Image modification\n",
        "from PIL import Image, ImageFont, ImageDraw # In case we need to modify the image\n",
        "import textwrap\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58TrPxUilPtc"
      },
      "outputs": [],
      "source": [
        "# Load the models\n",
        "\n",
        "# Text summarizer\n",
        "\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "#tokenizer = PegasusTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "#model = PegasusForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Named Entity Recognition\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "# Image Generation\n",
        "pipe = DiffusionPipeline.from_pretrained(\"naclbit/trinart_characters_19.2m_stable_diffusion_v1\")\n",
        "#pipeline = DiffusionPipeline.from_pretrained(\"eimiss/EimisAnimeDiffusion_1.0v\")\n",
        "\n",
        "# Scheduler for Diffusion Model ---> fastest by now is DPMSolverMultistepScheduler (Stable_Diffusions_2)\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "#pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)\n",
        "\n",
        "# Generator --> Use the manual_seed attribute to select and fix a seed. This helps ensuring coherence in the style of the outputs\n",
        "generator = torch.Generator().manual_seed(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYX3JnjqjNrC"
      },
      "outputs": [],
      "source": [
        "# Read the User input and save it in a dictionary\n",
        "def unpack_prompt(json_file):\n",
        "  story_prompt = json.load(json_file)\n",
        "  return story_prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_mood(genre):\n",
        "  palettes = {\"fantasy\":[\"light blue, grey and white\", \"indigo, orange, beige\", \"brown, green, turquoise\"], \"adventure\": [\"brown, maroon, olive green\", \"gold, teal, red\", \"green, lavender, purple\"], \"romantic\": [\"pink, brown, gold\", \"red, black, gold\", \"silver, blue, purple\"], \"horror\": [\"black, red, white\", \"orange, grey, yellow\", \"brown, silver, red\"]}\n",
        "  genre += \" in \" + random.choice(palettes[genre])\n",
        "  return genre\n"
      ],
      "metadata": {
        "id": "9jFbG6UwNKv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfrCJY-7k1HJ"
      },
      "outputs": [],
      "source": [
        "# Summarize the text of the chapter to get only the most important parts of the story\n",
        "\n",
        "text =\"To Sherlock Holmes she is always the woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirable things for the observer—excellent for drawing the veil from men’s motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\"\n",
        "\n",
        "def summarize_text(chapter, summarizer, nlp):\n",
        "\n",
        "  '''\n",
        "  param: chapter --> string with the current chapter text\n",
        "  param: summarizer --> summarization model (BART)\n",
        "\n",
        "  output: list of max 3 summarized sentences\n",
        "\n",
        "  '''\n",
        "  # Generate summary of the chapter\n",
        "  summary = summarizer(chapter, max_length=130, min_length=30, do_sample=False)\n",
        "  sents = summary[0]['summary_text']\n",
        "\n",
        "\n",
        "  # Pick only 3 sentences (to generate only 3 images for every chapter)\n",
        "  sentences = sent_tokenize(sents)\n",
        "  if len(sentences) > 3:\n",
        "    sentences = random.sample(sentences, 3)\n",
        "\n",
        "  return sentences\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "sum_text = summarize_text(text,summarizer, nlp)\n",
        "print(sum_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdGYVKuzo0ro"
      },
      "outputs": [],
      "source": [
        "# def Named Entity Recognition + References finden\n",
        "# Schon ersätzen in den Sätzen\n",
        "\n",
        "def named_entity_recognition(sentence, nlp):\n",
        "\n",
        "  doc = nlp(sentence)\n",
        "  per_entities = []\n",
        "  loc_entities = []\n",
        "  actions = [\"\",\"\", \"\", \"\"]      #(verb, direct object, adverb, attribute)\n",
        "  persons = []\n",
        "  print(doc._.has_coref)\n",
        "  print(doc._.coref_clusters)\n",
        "\n",
        "\n",
        "\n",
        "  # extract characters and locations\n",
        "  for ent in doc.ents:\n",
        "    if ent.label_ == \"PERSON\":\n",
        "      persons.append(ent)\n",
        "    if ent.label_ == (\"LOC\" or \"GPE\" or \"FAC\"):\n",
        "      loc_entities.append(ent)\n",
        "\n",
        "  # extract actions\n",
        "  for token in doc:\n",
        "\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)\n",
        "    if token.dep_ == \"nsubj\":\n",
        "      if len(persons)== 0:\n",
        "        per_entities.append(token)\n",
        "      else:                         #Check if Subject is a detected Person, include otherwise\n",
        "          is_person = False\n",
        "          for p in persons:\n",
        "            if token in p:\n",
        "              is_person = True\n",
        "              per_entities.append(p)\n",
        "          if is_person == False:\n",
        "            per_entities.append(token)\n",
        "\n",
        "\n",
        "    # Added negation\n",
        "    if token.dep_ == \"neg\":\n",
        "      actions[0] = token\n",
        "    if token.dep_ == \"ROOT\":\n",
        "      actions[1] = token\n",
        "    if token.dep_ == \"dobj\":\n",
        "      actions[3] = token\n",
        "    if token.dep_ == \"acomp\" and actions[1].lemma_==\"be\":\n",
        "      actions[2] = token\n",
        "    if token.dep_ == \"attr\" and actions[1].lemma_==\"be\":\n",
        "      actions[3] = token\n",
        "\n",
        "\n",
        "\n",
        "  return per_entities, loc_entities, actions\n",
        "\n",
        "\n",
        "\n",
        "sum_text = [\"Sam and Tom go to the beach. Sam sees a shark. Sam tells Tom.\"]\n",
        "\n",
        "extracted_infos = [named_entity_recognition(sent, nlp) for sent in sum_text]\n",
        "print(extracted_infos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_prompts(sentences, nlp, characters, time, genre):\n",
        "  prompts = []\n",
        "\n",
        "  for sent in sentences:\n",
        "    curr_prompt = \"\"\n",
        "    char_entities, loc_entities, actions = named_entity_recognition(sent, nlp)\n",
        "    for character in char_entities:\n",
        "      # Need to check if the character name recognized through NER is included in the key name\n",
        "      is_character = False\n",
        "      for char in characters.keys():\n",
        "        if str(character) in char:\n",
        "          curr_prompt += str(character)+ \", \" + characters[char] +\", \"\n",
        "          is_character = True\n",
        "      if not is_character:\n",
        "        curr_prompt += str(character) + \", \"\n",
        "\n",
        "    for action in actions:\n",
        "      curr_prompt += str(action) + \" \"\n",
        "\n",
        "    for place in loc_entities:\n",
        "          curr_prompt += \", \" + str(place)\n",
        "    curr_prompt += \", \" +time\n",
        "    curr_prompt += \", \" + genre\n",
        "\n",
        "    prompts.append(curr_prompt)\n",
        "  return prompts\n",
        "cs = {\"Tom\": \"man, brown hair , blue eyes\", \"Sam\": \"male, black hair, brown eyes\"}\n",
        "prepare_prompts(sum_text, nlp, cs, \"modern\", set_mood(\"fantasy\"))"
      ],
      "metadata": {
        "id": "5lTsVgcezIPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZO_7IWM5--q"
      },
      "outputs": [],
      "source": [
        "# Negative prompt\n",
        "n_prompt = \"lowres, NSFW, bad anatomy, bad hands, text, error, missing fingers, cropped, jpeg artifacts, worst quality, low quality, signature, watermark, blurry, deformed, extra ears, deformed, disfigured, mutation, censored\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWggR4SvgGo4"
      },
      "outputs": [],
      "source": [
        "def generate_images(prompts):\n",
        "  images = []\n",
        "  for p in prompts:\n",
        "    img =pipe(prompt=p, negative_prompt=n_prompt,generator=generator, num_inference_steps = 7).images[0]\n",
        "    if not img.getbbox():\n",
        "      print(\"NSFW content\")\n",
        "    else:\n",
        "      images.append(img)\n",
        "  return images\n",
        "\n",
        "ims = generate_images(ps)\n",
        "ims[0].show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ims[0]"
      ],
      "metadata": {
        "id": "1XBg2xiGBpmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7ojfpMgdHMt"
      },
      "outputs": [],
      "source": [
        "# AWS Student Developer Account free credits\n",
        "# Look at \"Merry the Scientist\"\n",
        "# Look at the seed of the Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpToLNQN71pM"
      },
      "outputs": [],
      "source": [
        "def add_text(img, sent):\n",
        "  \"\"\"Adds a sentence in on a white space at the bottom of the picture.\"\"\"\n",
        "  draw = ImageDraw.Draw(img)\n",
        "  sent = textwrap.fill(sent, img.size[0]//6)      # Cut Sentence to the length of the picture\n",
        "  text_h  = draw.textsize(sent)[1]       #get height of text\n",
        "  new_size = (img.size[0], img.size[1]+text_h)\n",
        "  new_image = Image.new('RGB', new_size, (255, 255, 255)) #slightly larger white background\n",
        "  new_image.paste(img)\n",
        "\n",
        "  #add text into white area\n",
        "  h = new_image.size[1]                 #get height of image\n",
        "  ImageDraw.Draw(new_image).text(( 0, h-text_h), sent, (0,0,0))\n",
        "\n",
        "  #return result\n",
        "  return new_image\n",
        "\n",
        "def make_gif(images):\n",
        "  \"\"\"takes list of images and saves them as a gif\"\"\"\n",
        "  frame_one = images[0]\n",
        "  w, h = images[0].size\n",
        "  ims = [i.resize((w, h)) for i in images]\n",
        "  frame_one.save(\"my_gif.gif\", format=\"GIF\", append_images=ims, save_all=True, duration=5000, loop=0)\n",
        "\n",
        "text_ims = []\n",
        "for i in range(len(ims)):\n",
        "  text_ims.append(add_text(ims[i], sum_text[i]))\n",
        "make_gif(text_ims)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHU0Bnlr8hqJ"
      },
      "outputs": [],
      "source": [
        "def handler(json_file):\n",
        "\n",
        "  # 1) create the story_prompt object by unpacking the JSON file\n",
        "  story_prompt = unpack_prompt(json_file)\n",
        "\n",
        "  # 2) summarize chapter text\n",
        "  summarized_text = summarize_text(story_prompt[\"chapter\"], summarizer, nlp)\n",
        "\n",
        "  # 3) prepare prompt --> extract the characters description, the background etc.\n",
        "  prompts = prepare_prompts(summarized_text, nlp, story_prompt[\"characters\"], story_prompt[\"time\"], story_prompt[\"genre\"])\n",
        "\n",
        "\n",
        "\n",
        "# Extract characters and places named in the chapter (for the background)\n",
        "  char_entities, loc_entities = named_entity_recognition(summary, nlp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H-odSAX79Tb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "char_1 = Image.open(\"img1.png\")\n",
        "resized_char = char_1.resize((200,200))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}